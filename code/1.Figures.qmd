---
title: "Paper Figures"
date: "`r Sys.Date()`"
format: html
execute:
  echo: true
---

## Figures for the paper

```{r}
pacman::p_load(
  pacman, dplyr, tidyverse, fixest, parallel, foreach, doParallel, cubelyr, tigris,
  zoo, SCI, purrr, ncdf4, stringr, lubridate, data.table, tidyr,
  tidyUSDA, keyring, FedData, daymetr, ggplot2, tmap, future.apply, CropScapeR, prism, exactextractr
)
rm(list = ls())

# Setting USDA-NASS key
usdarnass::nass_set_key(key = "79F68508-887F-3423-A3EE-F60AB7DFB3AE")
```

### Figure 1. US historical steer finishing weights and beef cow head numbers (2000-2024).

```{r}
begin <- "1950-01-15" %>% as.Date()
end <- Sys.Date()
report_time_analysis <- paste0(begin, ":", end)

# Cattle outweight
OUTWT_USDA_quantity <- usdampr::mpr_request(slugIDs = "2477", report_time = report_time_analysis)$Detail %>% 
  tidyr::separate(., selling_basis_description, c("selling_type", "selling_transportation")) %>% 
  dplyr::filter(., class_description == "STEER", grade_description == "Total all grades", selling_type == "LIVE", selling_transportation == "FOB") %>%
  dplyr::mutate(., date = {report_date %m-% months(1)}, year = {year(date)}, month = {month(date)}) %>%
  dplyr::select(., date, year, month, report_title, class_description, grade_description, selling_type, selling_transportation, head_count, weight_range_avg, weighted_avg_price) %>%
  dplyr::arrange(., year, month) %>% dplyr::mutate(., steer_live_OTWT = weight_range_avg) %>% 
  dplyr::select(., year, month, steer_live_OTWT) %>% 
  group_by(year, month) %>% 
  summarize(., steer_live_OTWT = mean(steer_live_OTWT))

OUTWT_USDA_quantity <- OUTWT_USDA_quantity %>% 
  dplyr::mutate(., marketed_date = make_date(year, month, 15),
                purchased_date = {marketed_date %m-% months(4)},
                year_purch = {year(purchased_date)}, 
                month_purch = {month(purchased_date)}) %>% 
  na.omit()


# Cattle # of head
slaughter_head <- usdarnass::nass_data(source_desc = "SURVEY", sector_desc = "ANIMALS & PRODUCTS", group_desc = "LIVESTOCK",
                                       commodity_desc = "CATTLE",
                                       short_desc = "CATTLE, COWS, BEEF - INVENTORY", 
                                       agg_level_desc = "NATIONAL", year = "1990=<") %>% 
  dplyr::select(.,  year = year, month = end_code, beef_head = Value) %>% 
  dplyr::mutate(., year = {year %>% as.numeric()}, month = {month %>% as.numeric()}, 
                beef_head = {as.numeric(gsub(",","",beef_head))}) %>% 
  dplyr::filter(month == 1) %>%
  dplyr::mutate(beef_head = dplyr::lag(beef_head)) %>% na.omit()

slaughter_head <- slaughter_head %>% 
  dplyr::mutate(., marketed_date = make_date(year, month, 15),
                purchased_date = {marketed_date %m-% months(4)},
                year_purch = {year(purchased_date)}, 
                month_purch = {month(purchased_date)}) %>% 
  na.omit()


# Filter both datasets to start from the minimum common date
min_date <- max(min(OUTWT_USDA_quantity$marketed_date), min(slaughter_head$marketed_date))
OUTWT_USDA_quantity_filtered <- OUTWT_USDA_quantity %>% 
  dplyr::filter(marketed_date >= min_date) %>% 
  group_by (year) %>% 
  summarize(steer_live_OTWT_annual = mean(steer_live_OTWT, na.rm = TRUE))

slaughter_head_filtered <- slaughter_head %>%
  dplyr::filter(marketed_date >= min_date) %>% 
  dplyr::mutate(beef_head_2 = beef_head/1000)
scaling_factor <- 23.07692


# Figure 1
ggplot() +
  geom_line(data = OUTWT_USDA_quantity_filtered, aes(x = year, y = steer_live_OTWT_annual, color = "Steer, live weight")) +  
  geom_line(data = slaughter_head_filtered, aes(x = year, y = beef_head_2 / scaling_factor, color = "Beef cow, head")) +  
  xlab("Year") + 
  theme_bw() + 
  labs(title = "") + 
  ylab("Steer, live finishing weight (lbs)") +
  scale_y_continuous(
    name = "Steer, live finishing weight (lbs)",
    sec.axis = sec_axis(~ . * scaling_factor, name = "Beef cow, head count (1'000)")  # Multiply back the scaled beef_head for the secondary y-axis
  ) +
  scale_color_manual(values = c("Steer, live weight" = "black", "Beef cow, head" = "red"),  # Manually assign colors
                     name = "") +  # Legend title
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10),
        axis.title.y = element_text(size = 10),
        axis.title.y.right = element_text(size = 10),  
        axis.text.y = element_text(size = 10),
        legend.position.inside = c(0.2, 0.9),  # Position the legend inside the plot at coordinates (0.8, 0.8)
        legend.background = element_rect(fill = alpha('white', 0.5)),
        legend.text = element_text(size = 12),  # Set legend text size
        legend.title = element_text(size = 14))   # Make legend background semi-transparent


```

### Figure 2. Annual US national beef cow inventory and pastureland data.

```{r}
#| echo: false


## PASTURE LAND - from USDA NASS quickStats
pasture_land_total <- usdarnass::nass_data(source_desc = "CENSUS", sector_desc = "ECONOMICS", group_desc = "FARMS & LAND & ASSETS",
                                      commodity_desc = "AG LAND", statisticcat_desc = "AREA", short_desc = "AG LAND, PASTURELAND - ACRES",
                                      domain_desc = "TOTAL", agg_level_desc = "NATIONAL", year = "1990<=") %>% 
  dplyr::select(., state_name, county_name, year, Value) 

pasture_land_total <- rename(pasture_land_total, state = state_name)
pasture_land_total <- rename(pasture_land_total, county = county_name)
pasture_land_total <- rename(pasture_land_total, pastureland_all_types = Value)


# PASTURE LAND - from PDFs (before 1997)
pasture_data_PDF <- readxl::read_xlsx('/Users/sharaakat/Dropbox/akat_shara/DWFI_drought/GitHub/Data/Data/pasture_data_FINAL.xlsx')


# Join all PASTURELAND data
pasture_data_ALL <- rbind(pasture_data_PDF, pasture_land_total)
pasture_data_ALL$year <- as.numeric(as.character(pasture_data_ALL$year))
pasture_data_ALL$pastureland_all_types <- gsub(",", "", pasture_data_ALL$pastureland_all_types)
pasture_data_ALL$pastureland_all_types <- as.numeric(as.character(pasture_data_ALL$pastureland_all_types))
pasture_data_ALL$state <- tolower(pasture_data_ALL$state)
pasture_data_ALL$county <- tolower(pasture_data_ALL$county)


# Create ANNUAL pastureland data - ALL US
pasture_data_ALL_US <- pasture_data_ALL %>% 
  group_by(year) %>%
  summarise(
    total_pastureland_all_types = sum(pastureland_all_types, na.rm = TRUE)
  )



## CATTLE INV - from USDA NASS quickStats
beef_inv_total <- usdarnass::nass_data(source_desc = "CENSUS", sector_desc = "ANIMALS & PRODUCTS", group_desc = "LIVESTOCK",
                                      commodity_desc = "CATTLE", statisticcat_desc = "INVENTORY", short_desc = "CATTLE, COWS, BEEF - INVENTORY",
                                      domain_desc = "TOTAL",  agg_level_desc = "NATIONAL", year = "1990<=") %>% 
  dplyr::select(., state_name, county_name, year, Value) %>% 
  rename(beef_inv = Value,
         state = state_name,
         county = county_name)


# CATTLE INV - from PDFs (before 1997)
beef_inv_PDF <- readxl::read_xlsx('/Users/sharaakat/Dropbox/akat_shara/DWFI_drought/GitHub/Data/Data/county_beefinv.xlsx')


# Join all CATTLE INV. data
beef_inv <- rbind(beef_inv_PDF, beef_inv_total)
beef_inv$year <- as.numeric(as.character(beef_inv$year))
beef_inv$beef_inv <- gsub(",", "", beef_inv$beef_inv)
beef_inv$beef_inv <- as.numeric(as.character(beef_inv$beef_inv))
beef_inv$state <- tolower(beef_inv$state)
beef_inv$county <- tolower(beef_inv$county)


# Create ANNUAL cattle inventory data - ALL US
beef_inv_total_US <- beef_inv %>% 
  group_by(year) %>%
  summarise(
    beef_inv = sum(beef_inv, na.rm = TRUE)
  )



# Figure 2
merged_ALL_national <- left_join(pasture_data_ALL_US, beef_inv_total_US, by = c("year"))

merged_ALL_national$beef_inv <- merged_ALL_national$beef_inv/1000000
merged_ALL_national$total_pastureland_all_types <- merged_ALL_national$total_pastureland_all_types/1000000
scaling_factor <- max(merged_ALL_national$total_pastureland_all_types) / max(merged_ALL_national$beef_inv)


ggplot() +
  geom_line(data = merged_ALL_national, aes(x = year, y = beef_inv, color = "Beef cow inventory, head")) +  # Assign legend label
  geom_line(data = merged_ALL_national, aes(x = year, y = total_pastureland_all_types / scaling_factor, color = "Pastureland (all), acres")) +  # Assign legend label and scaling factor
  xlab("Year") + 
  theme_bw() + 
  labs(title = "") + 
  # ylab("Steer, live finishing weight (lbs)") +
  scale_x_continuous(breaks = seq(min(merged_ALL_national$year), max(merged_ALL_national$year), by = 5)) +  # Show year as numeric on x-axis
  scale_y_continuous(
    name = "Beef cow inventory, head (mln)",
    sec.axis = sec_axis(~ . * scaling_factor, name = "Pastureland (all), acres (mln)")  # Multiply back the scaled beef_head for the secondary y-axis
  ) +
  scale_color_manual(values = c("Beef cow inventory, head" = "black", "Pastureland (all), acres" = "red"),  # Manually assign colors
                     name = "") +  # Legend title
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10),
        axis.title.y = element_text(size = 10),
        axis.title.y.right = element_text(size = 10),  
        axis.text.y = element_text(size = 10),
        legend.position = c(0.8, 0.8),  # Position the legend inside the plot at coordinates (0.2, 0.8)
        legend.background = element_rect(fill = alpha('white', 0.5)),
        legend.text = element_text(size = 12),  # Set legend text size
        legend.title = element_text(size = 14))   # Make legend background semi-transparent

```

### Figure 3. Marginal effects of temperature on hay yield (Douglas County, Kansas).

```{r}

## Hay Yield -  DATA
# ANNUAL TONS/ACRE (KANSAS, DOUGLAS COUNTY)
hay_yield <- read.csv("/Users/sharaakat/Dropbox/akat_shara/DWFI_drought/GitHub/RobustnessCheck/Data/HAY_historical.csv") %>% 
  dplyr::select(Year, Value) %>% 
  rename(DryYield = Value) 

hay_yield <- hay_yield %>% 
  mutate(Trend = seq(1, nrow(hay_yield), 1),
         ly = log(DryYield))


## Weather -  DATA
# Create weather data
weather <- readstata13::read.dta13("/Users/sharaakat/Dropbox/akat_shara/DWFI_drought/GitHub/RobustnessCheck/Data/Weather_fips20191.dta")

weather <- weather %>% 
  dplyr::mutate(., 
                Year = {dateNum %>% lubridate::year(.)},
                Mon  = {dateNum %>% lubridate::month(.)},
                Day  = {dateNum %>% lubridate::day(.)})

# March to October Growing Season - example for a single day
weather <- weather %>% 
  dplyr::filter(., 
                Mon >= 3, Mon <= 10)


#merge in grid weights
weather <- weather %>% dplyr::mutate(., tAvg = (tMax + tMin)/2)

weather_list_temp <- list
weather_list_temp <- lapply(seq(0,45,1), function(i){
  
   w <- weather %>%
    dplyr::mutate(!!paste0("time", i, "C") := dplyr::case_when( tMax <= i ~ 0,
                                                                i <= tMin ~ 1,
                                                                TRUE ~ acos((2*i - tMax - tMin)/(tMax - tMin))/base::pi)) 
    w %>% dplyr::select(., !!paste0("time", i, "C")) 
})

weather <- weather_list_temp %>% do.call("cbind",.) %>% cbind(weather, .) #combine binned weather data with weather temp data generated


weather_list_exp <- list
weather_list_exp <- lapply(seq(from = 0, to = 44, by = 1), function(j){
  
  w <- weather %>%
    dplyr::mutate(., !!paste0("exp", j) := get(paste0("time", j, "C")) - get(paste0("time", j+1, "C")))
    w %>% dplyr::select(., !!paste0("exp", j)) 
})

weather <- weather_list_exp %>% do.call("cbind", .) %>% cbind(weather, .)

# degree days above some threshold
weather_list_dday <- list
weather_list_dday <- lapply(seq(from = 0, to = 45, by = 1), function(k){
  
  w <- weather %>%
    dplyr::mutate(tAvg = (tMin + tMax)/2,
                  tempSave = acos((2*k - tMax - tMin)/(tMax - tMin)),
                  !!paste0("dday", k, "C") := dplyr::case_when( tMax <= k ~ 0,
                                                                k <= tMin ~ tAvg - k,
                                                                TRUE ~ ( (tAvg - k)*(tempSave) + (tMax - tMin)*sin(tempSave)/2)/base::pi))
  
  w %>% dplyr::select(., !!paste0("dday", k, "C"))
})

weather <- weather_list_dday %>% do.call("cbind", .) %>% cbind(weather, .)
rm(weather_list_dday, weather_list_exp, weather_list_temp)

#collapse by aggregation level, weighted average across grids;
# temp_weather_mean <- weather %>% 
#   group_by(dateNum, Year) %>%
#   summarise_at(.tbl = ., .vars = vars(tMax, tMin, tAvg), funs(weighted.mean(x = ., w = cropArea)))

temp_weather_mean <- weather %>% 
  group_by(dateNum, Year) %>%
  summarise_at(.tbl = ., .vars = vars(tMax, tMin, tAvg), funs(mean(x = ., na.rm = TRUE)))

# temp_agg_mean <- weather %>%
#   group_by(dateNum, Year) %>%
#   summarise_at(.tbl = ., .vars = vars(prec, time0C:time45C, exp0:exp44, dday0C:dday45C), funs(weighted.mean(x = ., w = cropArea)))

temp_agg_mean <- weather %>%
  group_by(dateNum, Year) %>%
  summarise_at(.tbl = ., .vars = vars(prec, time0C:time45C, exp0:exp44, dday0C:dday45C), funs(mean(x = ., na.rm = TRUE)))


temp_weather_year <- temp_weather_mean %>% 
  group_by(Year) %>%
  summarise_at(.tbl = ., .vars = vars(tMin, tMax, tAvg), funs(mean(.)))

temp_agg_year <- temp_agg_mean %>%
  group_by(Year) %>%
  summarise_at(.tbl = ., .vars = vars(prec, exp0:exp44, dday0C:dday45C), funs(sum(.)))


#create master-level weather dataset
weatherData <- temp_weather_year %>% dplyr::left_join(x = ., y = temp_agg_year, by = c("Year"))


#merge yield and weather data
MergedYieldWeather <- hay_yield %>% dplyr::inner_join(x = ., y = weatherData, by =c("Year")) %>%
  dplyr::mutate(., Year = as.factor(Year))

#create bins which are 3C wide
exp_bins_3C_list <- list()
exp_bins_3C_list <- lapply(seq(from = 0, to = 36, by = 3), function(b){
  #create exposure bins
  ip1 = b + 1
  ip2 = b + 2

  w <- MergedYieldWeather %>%
    dplyr::mutate(., !!paste("bin", b, ip2, sep = "_") := get(paste("exp", b, sep ="")) + get(paste("exp", ip1, sep ="")) + get(paste("exp", ip2, sep = "")))
  w %>% dplyr::select(., !!paste("bin", b, ip2, sep = "_"))
})

MergedYieldWeather <- exp_bins_3C_list %>% do.call("cbind", .) %>% cbind(MergedYieldWeather, .) %>%
  dplyr::mutate(., !!paste("bin", "39", "inf", sep = "_") := {dplyr::select(., exp39:exp44) %>% apply(.,1,sum)})

#estimate panel model clustered by Year
yield_lm_1 <- lm(formula = ly ~ poly(Trend, degree = 2) + poly(prec, degree = 2) + 
                   bin_0_2 + bin_3_5 + bin_6_8 + bin_9_11 + bin_12_14 + bin_15_17 + bin_18_20 + 
                   bin_21_23 + bin_24_26 + bin_27_29 + bin_30_32 + bin_33_35 + bin_36_38 + bin_39_inf,
                 data = MergedYieldWeather)
yield_lm_1$clse <- multiwayvcov::cluster.vcov(yield_lm_1, MergedYieldWeather$Year)
yield_lm_1_cluster_year_output <- lmtest::coeftest(yield_lm_1, yield_lm_1$clse) %>% round(.,4)

#Estimate the optimal knots (i.e. cut points) for a piecewise linear function
optimal_knots = list()
optimal_knots <- lapply(seq(from = 10, to = 20, by = 1), function(c1){
  lapply(seq(from = 29, to = 35, by = 1), function(c2){
    w <- MergedYieldWeather %>% dplyr::mutate(., !!paste("dday0", c1, sep = "_") := get("dday0C") - get(paste("dday", c1, "C", sep = "")),
                                              !!paste("dday", c1, c2, sep = "_") := get(paste("dday",c1, "C", sep = "")) - get(paste("dday", c2, "C", sep = "")),
                                              !!paste("dday", c2, "inf", sep = "_") := get(paste("dday",c2, "C", sep = ""))) %>% 
      dplyr::mutate(., Trend2 = {Trend^2}, prec2 = {prec^2}) %>%
      dplyr::select(., ly, Trend, Trend2, prec, prec2,
                    !!paste("dday0", c1, sep = "_"),
                    !!paste("dday", c1, c2, sep = "_"),
                    !!paste("dday", c2, "inf", sep = "_")) %>%
      lm(formula = ly ~ ., data = .) %>% summary %>% {.$r.squared}
    
    cbind(c1,c2,w)
    
  })
})

#create data.frame with cut values and Rsq
Rsq_10 <- lapply(1:11, function (i) {
  optimal_knots[[i]] %>% do.call(rbind,.) %>% matrix(., ncol = 3)
  }) %>% 
  do.call("rbind",.) %>% as.data.frame() %>% dplyr::rename(., cut1 = V1, cut2 = V2, Rsq = V3)

#find the max Rsq and return the cut values 
optimal_cut <- Rsq_10[which.max(Rsq_10$Rsq),]

#use these cut values to create bins -> estimate piecewise regression clustered at the year level
reg_data_preferred <- MergedYieldWeather %>% dplyr::mutate(., !!paste("dday", "0", optimal_cut$cut1, sep = "_") := get("dday0C") - get(paste("dday", optimal_cut$cut1, "C", sep = "")),
                                                           !!paste("dday", optimal_cut$cut1, optimal_cut$cut2, sep = "_") := get(paste("dday",optimal_cut$cut1, "C", sep = "")) - get(paste("dday", optimal_cut$cut2, "C", sep = "")),
                                                           !!paste("dday", optimal_cut$cut2, "inf", sep = "_") := get(paste("dday",optimal_cut$cut2, "C", sep = ""))) %>% 
  dplyr::mutate(., Trend2 = {Trend^2}, prec2 = {prec^2}) %>%
  dplyr::select(., ly, Trend, Trend2, prec, prec2,
                !!paste("dday", "0", optimal_cut$cut1, sep = "_"),
                !!paste("dday", optimal_cut$cut1, optimal_cut$cut2, sep = "_"),
                !!paste("dday", optimal_cut$cut2, "inf", sep = "_"))

yield_lm_1_optimal_cut <-  reg_data_preferred %>%
  lm(formula = ly ~ ., data = .)
yield_lm_1_optimal_cut$clse <- multiwayvcov::cluster.vcov(yield_lm_1_optimal_cut, MergedYieldWeather$Year)
yield_lm_1_optimal_cut_cluster_year_output <- lmtest::coeftest(yield_lm_1_optimal_cut, yield_lm_1_optimal_cut$clse)


#Piecewise linear marginal effect of temp
#Need to fix the way the SEmargeff is calculated
reg_data_preferred <- reg_data_preferred %>% dplyr::mutate(., 
                                     temp = seq(from = 0, to = nrow(.)-1, by = 1),
                                     I0 = 1, 
                                     I10 = case_when(temp < 10 ~ 0, TRUE ~ 1), 
                                     I30 = case_when(temp < 32 ~ 0, TRUE ~ 1),
                              margeff = (1-I10)*(yield_lm_1_optimal_cut_cluster_year_output[6,1]*(temp-0)) 
                              + (I10)*(1-I30)*(yield_lm_1_optimal_cut_cluster_year_output[6,1]*(10) + yield_lm_1_optimal_cut_cluster_year_output[7,1]*(temp-10))
                              + (I30)*(yield_lm_1_optimal_cut_cluster_year_output[6,1]*(10) + yield_lm_1_optimal_cut_cluster_year_output[7,1]*(30-10) + yield_lm_1_optimal_cut_cluster_year_output[8,1]*(temp-30)),
                              SEmargeff = 0.013,
                              Lower = margeff - 1.96*SEmargeff,
                              Upper = margeff + 1.96*SEmargeff)

# FIGURE 3
reg_data_preferred %>%
  dplyr::filter(., temp <= 45) %>%
  # dplyr::select(., temp, margeff, Lower, Upper) %>% 
  # reshape2::melt(., id = "temp") %>%
  ggplot(., aes(x = temp, y = margeff)) +
  geom_line() +
  geom_point() +
  scale_colour_discrete("") +
  scale_linetype_manual("", values=c(1,2,1,2)) +
  scale_shape_manual("", values=c(17,17,16,16)) + theme_classic() +
  xlab("Temperature (C)") +  ylab ("Hay Log-yield (tons/acre)") 

```


### Figure 4. Marginal effects of temperature on hay yield (Douglas County, Kansas).

```{r}

# # 1.1 Pr data
# # 4.5, pr: 2006-2099, daily
# urls <- c(
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_pr_bcc-csm1-1_r1i1p1_rcp45_2006_2025_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_pr_bcc-csm1-1_r1i1p1_rcp45_2026_2045_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_pr_bcc-csm1-1_r1i1p1_rcp45_2046_2065_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_pr_bcc-csm1-1_r1i1p1_rcp45_2066_2085_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_pr_bcc-csm1-1_r1i1p1_rcp45_2086_2099_CONUS_monthly.nc"
# )
# 
# 
# dir.create("./data", showWarnings = FALSE)
# 
# # Loop to download and extract each file
# for (url in urls) {
#   # Extract year range from the URL for naming the file
#   year_range <- gsub(".*_([0-9]{4}_[0-9]{4})_.*", "\\1", url)
# 
#   # Set destination file name
#   destfile <- paste0("./data/pr4.5", year_range, ".nc")
# 
#   # Increase timeout in case of large files
#   options(timeout = max(600, getOption("timeout")))
# 
#   # Download the file
#   download.file(url, destfile = destfile, method = "auto", mode = "wb")
# 
#   # Load the .nc file into a raster object
#   assign(paste0("pr4.5", year_range), terra::rast(destfile))
# 
#   # Print confirmation of download and extraction
#   print(paste("Downloaded and loaded:", destfile))
# }
# 
# 
# 
# 
# # 8.5, pr: 2006-2099, daily
# urls <- c(
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_pr_bcc-csm1-1_r1i1p1_rcp85_2006_2025_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_pr_bcc-csm1-1_r1i1p1_rcp85_2026_2045_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_pr_bcc-csm1-1_r1i1p1_rcp85_2046_2065_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_pr_bcc-csm1-1_r1i1p1_rcp85_2066_2085_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_pr_bcc-csm1-1_r1i1p1_rcp85_2086_2099_CONUS_monthly.nc"
# )
# 
# 
# dir.create("./data", showWarnings = FALSE)
# 
# # Loop to download and extract each file
# for (url in urls) {
#   # Extract year range from the URL for naming the file
#   year_range <- gsub(".*_([0-9]{4}_[0-9]{4})_.*", "\\1", url)
# 
#   # Set destination file name
#   destfile <- paste0("./data/pr8.5_", year_range, ".nc")
# 
#   # Increase timeout in case of large files
#   options(timeout = max(600, getOption("timeout")))
# 
#   # Download the file
#   download.file(url, destfile = destfile, method = "auto", mode = "wb")
# 
#   # Load the .nc file into a raster object
#   assign(paste0("pr8.5_", year_range), terra::rast(destfile))
# 
#   # Print confirmation of download and extraction
#   print(paste("Downloaded and loaded:", destfile))
# }
# 
# 
# 

# ## 1.2. tmin DATA
# 
# 
# # 4.5, tmin: 2006-2099, daily
# urls_tmin <- c(
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmin_bcc-csm1-1_r1i1p1_rcp45_2006_2025_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmin_bcc-csm1-1_r1i1p1_rcp45_2026_2045_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmin_bcc-csm1-1_r1i1p1_rcp45_2046_2065_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmin_bcc-csm1-1_r1i1p1_rcp45_2066_2085_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmin_bcc-csm1-1_r1i1p1_rcp45_2086_2099_CONUS_monthly.nc"
# )
# 
# dir.create("./data", showWarnings = FALSE)
# 
# # Loop to download and extract each file
# for (url in urls_tmin) {
#   # Extract year range from the URL for naming the file
#   year_range <- gsub(".*_([0-9]{4}_[0-9]{4})_.*", "\\1", url)
# 
#   # Set destination file name
#   destfile <- paste0("./data/tmin4.5_", year_range, ".nc")
# 
#   # Increase timeout in case of large files
#   options(timeout = max(600, getOption("timeout")))
# 
#   # Download the file
#   download.file(url, destfile = destfile, method = "auto", mode = "wb")
# 
#   # Load the .nc file into a raster object
#   assign(paste0("tmin4.5_", year_range), terra::rast(destfile))
# 
#   # Print confirmation of download and extraction
#   print(paste("Downloaded and loaded:", destfile))
# }
# 
# 
# 
# # 8.5, tmin: 2006-2099, daily
# urls_tmin <- c(
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmin_bcc-csm1-1_r1i1p1_rcp85_2006_2025_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmin_bcc-csm1-1_r1i1p1_rcp85_2026_2045_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmin_bcc-csm1-1_r1i1p1_rcp85_2046_2065_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmin_bcc-csm1-1_r1i1p1_rcp85_2066_2085_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmin_bcc-csm1-1_r1i1p1_rcp85_2086_2099_CONUS_monthly.nc"
# )
# 
# dir.create("./data", showWarnings = FALSE)
# 
# # Loop to download and extract each file
# for (url in urls_tmin) {
#   # Extract year range from the URL for naming the file
#   year_range <- gsub(".*_([0-9]{4}_[0-9]{4})_.*", "\\1", url)
# 
#   # Set destination file name
#   destfile <- paste0("./data/tmin8.5_", year_range, ".nc")
# 
#   # Increase timeout in case of large files
#   options(timeout = max(600, getOption("timeout")))
# 
#   # Download the file
#   download.file(url, destfile = destfile, method = "auto", mode = "wb")
# 
#   # Load the .nc file into a raster object
#   assign(paste0("tmin8.5_", year_range), terra::rast(destfile))
# 
#   # Print confirmation of download and extraction
#   print(paste("Downloaded and loaded:", destfile))
# }
# 
# 
# 
# ## 1.3. tmax DATA
# 
# 
# # 4.5, tmax: 2006-2099, daily
# urls_tmax <- c(
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmax_bcc-csm1-1_r1i1p1_rcp45_2006_2025_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmax_bcc-csm1-1_r1i1p1_rcp45_2026_2045_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmax_bcc-csm1-1_r1i1p1_rcp45_2046_2065_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmax_bcc-csm1-1_r1i1p1_rcp45_2066_2085_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmax_bcc-csm1-1_r1i1p1_rcp45_2086_2099_CONUS_monthly.nc"
# )
# 
# dir.create("./data", showWarnings = FALSE)
# 
# # Loop to download and extract each file
# for (url in urls_tmax) {
#   # Extract year range from the URL for naming the file
#   year_range <- gsub(".*_([0-9]{4}_[0-9]{4})_.*", "\\1", url)
# 
#   # Set destination file name
#   destfile <- paste0("./data/tmax4.5_", year_range, ".nc")
# 
#   # Increase timeout in case of large files
#   options(timeout = max(600, getOption("timeout")))
# 
#   # Download the file
#   download.file(url, destfile = destfile, method = "auto", mode = "wb")
# 
#   # Load the .nc file into a raster object
#   assign(paste0("tmax4.5_", year_range), terra::rast(destfile))
# 
#   # Print confirmation of download and extraction
#   print(paste("Downloaded and loaded:", destfile))
# }
# 
# 
# 
# 
# # 8.5, tmax: 2006-2099, daily
# urls_tmax <- c(
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmax_bcc-csm1-1_r1i1p1_rcp85_2006_2025_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmax_bcc-csm1-1_r1i1p1_rcp85_2026_2045_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmax_bcc-csm1-1_r1i1p1_rcp85_2046_2065_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmax_bcc-csm1-1_r1i1p1_rcp85_2066_2085_CONUS_monthly.nc",
#   "http://thredds.northwestknowledge.net:8080/thredds/fileServer/NWCSC_INTEGRATED_SCENARIOS_ALL_CLIMATE/macav2livneh/bcc-csm1-1/macav2livneh_tasmax_bcc-csm1-1_r1i1p1_rcp85_2086_2099_CONUS_monthly.nc"
# )
# 
# dir.create("./data", showWarnings = FALSE)
# 
# # Loop to download and extract each file
# for (url in urls_tmax) {
#   # Extract year range from the URL for naming the file
#   year_range <- gsub(".*_([0-9]{4}_[0-9]{4})_.*", "\\1", url)
# 
#   # Set destination file name
#   destfile <- paste0("./data/tmax8.5_", year_range, ".nc")
# 
#   # Increase timeout in case of large files
#   options(timeout = max(600, getOption("timeout")))
# 
#   # Download the file
#   download.file(url, destfile = destfile, method = "auto", mode = "wb")
# 
#   # Load the .nc file into a raster object
#   assign(paste0("tmax8.5_", year_range), terra::rast(destfile))
# 
#   # Print confirmation of download and extraction
#   print(paste("Downloaded and loaded:", destfile))
# }


## 2. Estimating Variables

# temp_base <- 12  # base temperature for GDD calculation
# temp_up <- 31  # threshold temperature for EDD calculation
# 
# # Load US counties
# US_counties <- tigris::counties(state = "US", cb = TRUE) %>%
#   st_as_sf()
# 
# # 2006, 2026, 2046, 2066, 2086
# month_year_data <- CJ(year = 2086)
# data_dir <- "/Volumes/Extreme SSD/UNL/DWFI/projection/data"
# 
# # Define file paths for 4.5 and 8.5 scenarios
# file_paths <- list(
#   `4.5` = list(
#     pr = list.files(path = data_dir, pattern = "pr4.5.*\\.nc$", full.names = TRUE),
#     tmin = list.files(path = data_dir, pattern = "tmin4.5.*\\.nc$", full.names = TRUE),
#     tmax = list.files(path = data_dir, pattern = "tmax4.5.*\\.nc$", full.names = TRUE)
#   ),
#   `8.5` = list(
#     pr = list.files(path = data_dir, pattern = "pr8.5.*\\.nc$", full.names = TRUE),
#     tmin = list.files(path = data_dir, pattern = "tmin8.5.*\\.nc$", full.names = TRUE),
#     tmax = list.files(path = data_dir, pattern = "tmax8.5.*\\.nc$", full.names = TRUE)
#   )
# )
# 
# # Function to process one month of data
# process_monthly_data <- function(year, scenario, file_paths, US_counties) {
#   # Load corresponding files for the scenario and year range
#   pr_file <- file_paths[[scenario]]$pr[grepl(sprintf("%d", year), file_paths[[scenario]]$pr)]
#   tmin_file <- file_paths[[scenario]]$tmin[grepl(sprintf("%d", year), file_paths[[scenario]]$tmin)]
#   tmax_file <- file_paths[[scenario]]$tmax[grepl(sprintf("%d", year), file_paths[[scenario]]$tmax)]
# 
#   # Check if all files exist
#   if (length(pr_file) == 0 || length(tmin_file) == 0 || length(tmax_file) == 0) {
#     message(sprintf("Skipping %d-%02d for %s scenario due to missing files.", year, month, scenario))
#     return(NULL)
#   }
# 
#   # Load raster data
#   pr_raster <- rast(pr_file)
#   tmin_raster <- rast(tmin_file)
#   tmax_raster <- rast(tmax_file)
# 
#   names(pr_raster) <- time(pr_raster)
#   names(tmin_raster) <- time(tmin_raster)
#   names(tmax_raster) <- time(tmax_raster)
#   
#   # Assign CRS to raster and vector dataset
#   US_counties_sf <- st_transform(US_counties, crs(pr_raster))
# 
#   # Extract data for each variable
#   pr_data <- as.data.table(terra::extract(pr_raster, vect(US_counties_sf)))
#   tmin_data <- as.data.table(terra::extract(tmin_raster, vect(US_counties_sf)))
#   tmax_data <- as.data.table(terra::extract(tmax_raster, vect(US_counties_sf)))
# 
#   # Reshape and aggregate data
#   pr_data_ID <- melt(pr_data, id.vars = "ID", variable.name = "Date", value.name = "ppt") %>%
#     .[, .(ppt = mean(ppt, na.rm = TRUE)), by = .(ID, Date)]
# 
#   tmin_data_ID <- melt(tmin_data, id.vars = "ID", variable.name = "Date", value.name = "tmin") %>%
#     .[, .(tmin = mean(tmin, na.rm = TRUE)), by = .(ID, Date)]
# 
#   tmax_data_ID <- melt(tmax_data, id.vars = "ID", variable.name = "Date", value.name = "tmax") %>%
#     .[, .(tmax = mean(tmax, na.rm = TRUE)), by = .(ID, Date)]
# 
#   setkey(pr_data_ID, ID, Date)
#   setkey(tmin_data_ID, ID, Date)
#   setkey(tmax_data_ID, ID, Date)
# 
#   
#   # Merge the data
#   weather_data <- merge(pr_data_ID, tmin_data_ID, by = c("ID", "Date"), all = TRUE)
#   weather_data <- merge(weather_data, tmax_data_ID, by = c("ID", "Date"), all = TRUE)
# 
#   # Add year and month
#   weather_data[, year := year(Date)]
#   weather_data[, month := month(Date)]
# 
#   US_counties_v_1 <- st_as_sf(vect(US_counties_sf)) %>%
#     mutate(ID = seq_len(nrow(.))) %>%
#     as.data.table()
# 
#   US_counties_v_1 <- merge(US_counties_v_1, weather_data, by = "ID", all.x = TRUE)
#   
#   US_counties_v_1[, tmax := tmax - 273.15]
#   US_counties_v_1[, tmin := tmin - 273.15]
# 
#   US_counties_v_1[, Tavg := (tmax + tmin) / 2]
#   US_counties_v_1[, month_heat_index := (Tavg / 5) ^ 1.514]
# 
#   # US_counties_v_2 <- US_counties_v_1[, .(annual_heat_index = sum(month_heat_index, na.rm = TRUE)), by = .(year, NAME, STATE_NAME)]
#   
#   US_counties_annual <- US_counties_v_1[, .(
#     annual_heat_index = sum(month_heat_index, na.rm = TRUE)
#   ), by = .(year, NAME, STATE_NAME)]
#   
#   US_counties_v_2 <-  merge(US_counties_v_1, US_counties_annual, by = c("year", "NAME", "STATE_NAME"), all.x = TRUE)
#   
#   US_counties_v_2[, a := 675 * 10^(-9) * annual_heat_index^3 - 771 * 10^(-7) * annual_heat_index^2 + 1792 * 10^(-5) * annual_heat_index + 0.49239]
# 
#   # joined_weather_SPEI <- merge(US_counties_v_1, US_counties_v_2, by = c("year", "NAME", "STATE_NAME"), all.x = TRUE)
#   US_counties_v_2[, PET := ifelse(Tavg <= 0, 0, 16 * ((10 * Tavg) / annual_heat_index) ^ a)]
#   US_counties_v_2[, D := ppt - PET]
# 
#   # joined_weather_SPEI[, Tavg := (tmax + tmin) / 2]
#   US_counties_v_2[, GDD := fifelse(Tavg < temp_base, 0,
#                                        fifelse(Tavg > temp_up, temp_up - temp_base,
#                                                Tavg - temp_base))]
# 
#   US_counties_v_2[, EDD := fifelse(tmax > temp_up, tmax - temp_up, 0)]
# 
#   print(sprintf("Done with year: %d", year))
# 
#   joined_weather <- US_counties_v_2[, .(
#     avg_tmin = tmin,
#     avg_tmax = tmax,
#     avg_tmean = Tavg,
#     sum_ppt = sum(ppt, na.rm = TRUE),
#     monthly_D = sum(D, na.rm = TRUE),
#     monthly_GDD = sum(GDD, na.rm = TRUE),
#     monthly_EDD = sum(EDD, na.rm = TRUE)
#   ), by = .(year, month, NAME, STATE_NAME)]
# 
#   return(joined_weather)
# }
# 
# # Process all data
# results <- list()
# for (scenario in names(file_paths)) {
#   scenario_results <- lapply(1:nrow(month_year_data), function(i) {
#     year <- month_year_data[i, year]
#     process_monthly_data(year, scenario, file_paths, US_counties)
#   })
#   results[[scenario]] <- do.call(rbind, scenario_results)
# }
# 
# # Save results
# saveRDS(results$`4.5`, file.path(data_dir, "2086_scenario_4.5_results.rds"))
# saveRDS(results$`8.5`, file.path(data_dir, "2086_scenario_8.5_results.rds"))


## 3. Combining datasets  

# # 4.5
# drought_2006_45 <- readRDS("/Volumes/Extreme SSD/UNL/DWFI/projection/data/2006_scenario_4.5_results.rds")
# drought_2026_45 <- readRDS("/Volumes/Extreme SSD/UNL/DWFI/projection/data/2026_scenario_4.5_results.rds")
# drought_2046_45 <- readRDS("/Volumes/Extreme SSD/UNL/DWFI/projection/data/2046_scenario_4.5_results.rds")
# drought_2066_45 <- readRDS("/Volumes/Extreme SSD/UNL/DWFI/projection/data/2066_scenario_4.5_results.rds")
# drought_2086_45 <- readRDS("/Volumes/Extreme SSD/UNL/DWFI/projection/data/2086_scenario_4.5_results.rds")
# 
# drought_data_4.5 <- rbind(drought_2006_45, drought_2026_45,
#                           drought_2046_45, drought_2066_45, drought_2086_45)
# saveRDS(drought_data_4.5, file.path(data_dir, "drought_4.5_ALL.rds"))
# 
# 
# 
# # 8.5
# drought_2006_85 <- readRDS("/Volumes/Extreme SSD/UNL/DWFI/projection/data/2006_scenario_8.5_results.rds")
# drought_2026_85 <- readRDS("/Volumes/Extreme SSD/UNL/DWFI/projection/data/2026_scenario_8.5_results.rds")
# drought_2046_85 <- readRDS("/Volumes/Extreme SSD/UNL/DWFI/projection/data/2046_scenario_8.5_results.rds")
# drought_2066_85 <- readRDS("/Volumes/Extreme SSD/UNL/DWFI/projection/data/2066_scenario_8.5_results.rds")
# drought_2086_85 <- readRDS("/Volumes/Extreme SSD/UNL/DWFI/projection/data/2086_scenario_8.5_results.rds")
# 
# drought_data_8.5 <- rbind(drought_2006_85, drought_2026_85,
#                           drought_2046_85, drought_2066_85, drought_2086_85)
# saveRDS(drought_data_8.5, file.path(data_dir, "drought_8.5_ALL.rds"))


## 4. Projected Hay Stocks

state_names <- c(
  AL = "Alabama", AK = "Alaska", AZ = "Arizona", AR = "Arkansas", CA = "California", 
  CO = "Colorado", CT = "Connecticut", DE = "Delaware", FL = "Florida", GA = "Georgia", 
  HI = "Hawaii", ID = "Idaho", IL = "Illinois", IN = "Indiana", IA = "Iowa", 
  KS = "Kansas", KY = "Kentucky", LA = "Louisiana", ME = "Maine", MD = "Maryland", 
  MA = "Massachusetts", MI = "Michigan", MN = "Minnesota", MS = "Mississippi", 
  MO = "Missouri", MT = "Montana", NE = "Nebraska", NV = "Nevada", NH = "New Hampshire", 
  NJ = "New Jersey", NM = "New Mexico", NY = "New York", NC = "North Carolina", 
  ND = "North Dakota", OH = "Ohio", OK = "Oklahoma", OR = "Oregon", PA = "Pennsylvania", 
  RI = "Rhode Island", SC = "South Carolina", SD = "South Dakota", TN = "Tennessee", 
  TX = "Texas", UT = "Utah", VT = "Vermont", VA = "Virginia", WA = "Washington", 
  WV = "West Virginia", WI = "Wisconsin", WY = "Wyoming"
)

# All hat stocks, 1000 tones
hay_all_stocks_1000t <- readxl::read_xlsx("/Users/sharaakat/Dropbox/akat_shara/DWFI_drought/GitHub/RobustnessCheck/Data/StateHaySupplies.xlsx", sheet = 2, skip = 2)

hay_all_stocks_1000t_2 <- pivot_longer(hay_all_stocks_1000t, cols = -year, names_to = "state", values_to = "hay_stock_1000t") %>% 
  mutate(state = state_names[state])

hay_all_stocks_1000t_2$state <- tolower(hay_all_stocks_1000t_2$state)

hay_all_stocks_1000t_3 <- hay_all_stocks_1000t_2 %>%
  group_by(state) %>%
  mutate(hay_stock_1000t = dplyr::lead(hay_stock_1000t, n = 1)) %>%  # Use lag with negative `n` to act like lead
  ungroup()

hay_all_stocks_1000t_national <- hay_all_stocks_1000t_3 %>% 
  group_by(year) %>% 
  summarize(hay_stock_1000t = mean(hay_stock_1000t, na.rm = TRUE)) 


# Calculate the last 5-year average of non-NA values
last_5_years_avg <- hay_all_stocks_1000t_national %>%
  filter(!is.na(hay_stock_1000t)) %>%
  tail(5) %>%
  summarise(avg = mean(hay_stock_1000t, na.rm = TRUE)) %>%
  pull(avg)

# Create a sequence of missing years (2023 to 2099)
missing_years <- tibble(
  year = 2023:2099,
  hay_stock_1000t = last_5_years_avg
)

# Combine the original data with the missing years
hay_all_stocks_1000t_national_projected <- hay_all_stocks_1000t_national %>%
  bind_rows(missing_years) %>%
  arrange(year)


## 5. Projected Stocking Density

# INITIAL MODEL
drought_final <- readRDS("/Users/sharaakat/Dropbox/akat_shara/DWFI_drought/GitHub/RobustnessCheck/Data/combined_1981_2020_NEW.rds")

growing_season_data <- drought_final %>%
  filter(month >= 3 & month <= 10)  # Select only March to October

# Aggregate to yearly level
yearly_drought_data <- growing_season_data %>%
  group_by(year, STATE_NAME, NAME) %>%  # Group by year, state, and county
  summarize(
    avg_tmin = mean(tmin, na.rm = TRUE),  # Average of minimum temperature
    avg_tmax = mean(tmax, na.rm = TRUE),  # Average of maximum temperature
    avg_tmean = mean(tmean, na.rm = TRUE),  # Average of mean temperature
    total_ppt = sum(ppt, na.rm = TRUE),  # Total precipitation
    total_D = sum(D, na.rm = TRUE),  # Total drought index
    total_GDD = sum(GDD, na.rm = TRUE),  # Total Growing Degree Days
    total_EDD = sum(EDD, na.rm = TRUE)  # Total Extreme Degree Days
  ) %>% 
  rename(state = STATE_NAME,
         county = NAME) %>% 
  dplyr::select(year, state, county, total_D, total_GDD, total_EDD)

yearly_drought_data$state <- tolower(yearly_drought_data$state)
yearly_drought_data$county <- tolower(yearly_drought_data$county)
joined_drought_hay <- left_join(yearly_drought_data, hay_all_stocks_1000t_national, by = c("year")) 

SR_data <- readRDS("/Users/sharaakat/Dropbox/akat_shara/DWFI_drought/GitHub/RobustnessCheck/Data/SR_data.rds")
regression_data <- left_join(SR_data, joined_drought_hay, by = c("year", "state", "county")) %>% 
  na.omit()
regression_data <- regression_data[!is.infinite(regression_data$stock_rate), ] %>%
  na.omit()

reg_1 <- feols(log(stock_rate) ~ total_D + total_GDD + total_EDD + hay_stock_1000t + hay_stock_1000t^2| county + state, 
               data = regression_data)

# 4.5
drought_data_4.5 <- readRDS("/Users/sharaakat/Dropbox/akat_shara/DWFI_drought/GitHub/RobustnessCheck/Data/drought_4.5_ALL.rds")
growing_season_data <- drought_data_4.5 %>%
  filter(month >= 3 & month <= 10)  # Select only March to October

# Aggregate to yearly level
yearly_drought_data_projected <- growing_season_data %>%
  group_by(year, STATE_NAME, NAME) %>%  # Group by year, state, and county
  summarize(
    total_D = sum(monthly_D, na.rm = TRUE),  # Total drought index
    total_GDD = sum(monthly_GDD, na.rm = TRUE),  # Total Growing Degree Days
    total_EDD = sum(monthly_EDD, na.rm = TRUE)  # Total Extreme Degree Days
  ) %>% 
  rename(state = STATE_NAME,
         county = NAME) %>% 
  dplyr::select(year, state, county, total_D, total_GDD, total_EDD)

yearly_drought_data_projected$state <- tolower(yearly_drought_data_projected$state)
yearly_drought_data_projected$county <- tolower(yearly_drought_data_projected$county)

joined_drought_hay_projected <- left_join(yearly_drought_data_projected, hay_all_stocks_1000t_national_projected, by = c("year")) 

Projected_45 <- predict(reg_1, newdata = joined_drought_hay_projected)
setDT(joined_drought_hay_projected)
joined_drought_hay_projected[, log_stock_rate := Projected_45]
Projected_SR_45 <- joined_drought_hay_projected[, stock_rate := exp(log_stock_rate)]



# 8.5
drought_data_8.5 <- readRDS("/Users/sharaakat/Dropbox/akat_shara/DWFI_drought/GitHub/RobustnessCheck/Data/drought_8.5_ALL.rds")
growing_season_data <- drought_data_8.5 %>%
  filter(month >= 3 & month <= 10)  # Select only March to October

# Aggregate to yearly level
yearly_drought_data_projected <- growing_season_data %>%
  group_by(year, STATE_NAME, NAME) %>%  # Group by year, state, and county
  summarize(
    total_D = sum(monthly_D, na.rm = TRUE),  # Total drought index
    total_GDD = sum(monthly_GDD, na.rm = TRUE),  # Total Growing Degree Days
    total_EDD = sum(monthly_EDD, na.rm = TRUE)  # Total Extreme Degree Days
  ) %>% 
  rename(state = STATE_NAME,
         county = NAME) %>% 
  dplyr::select(year, state, county, total_D, total_GDD, total_EDD)

yearly_drought_data_projected$state <- tolower(yearly_drought_data_projected$state)
yearly_drought_data_projected$county <- tolower(yearly_drought_data_projected$county)

joined_drought_hay_projected <- left_join(yearly_drought_data_projected, hay_all_stocks_1000t_national_projected, by = c("year")) 

Projected_85 <- predict(reg_1, newdata = joined_drought_hay_projected)
setDT(joined_drought_hay_projected)
joined_drought_hay_projected[, log_stock_rate := Projected_85]
Projected_SR_85 <- joined_drought_hay_projected[, stock_rate := exp(log_stock_rate)]


# FIGURE 4

# Calculate yearly means for both scenarios 
yearly_data_45 <- Projected_SR_45 %>%
  group_by(year) %>%
  summarise(mean_projected_stock_rate = mean(stock_rate, na.rm = TRUE)) %>%
  mutate(scenario = "RCP 4.5")  %>% 
  dplyr::filter(year >= 2020)

yearly_data_85 <- Projected_SR_85 %>%
  group_by(year) %>%
  summarise(mean_projected_stock_rate = mean(stock_rate, na.rm = TRUE)) %>%
  mutate(scenario = "RCP 8.5")  %>% 
  dplyr::filter(year >= 2020)

# Combine the datasets
combined_data <- bind_rows(yearly_data_45, yearly_data_85)

# Plot using ggplot2
ggplot(data = combined_data, aes(x = year, y = mean_projected_stock_rate, color = scenario)) +
  geom_line(linewidth = 1) +  # Line plot for each scenario
  geom_point(linewidth = 2) +  # Points for each year
  labs(
    x = "Year",
    y = "Projected Stock Rate",
    color = "Scenario"
  ) +
  scale_color_manual(values = c("RCP 4.5" = "blue", "RCP 8.5" = "red")) +  # Set colors for each scenario
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

```


